# -*- coding: utf-8 -*-
"""cadim pneumonia pna RAUNET

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_rjmMTLespZytwl5bFMe-ao7lI--OzeQ
"""

# Commented out IPython magic to ensure Python compatibility.
# % pip install -q jarvis-md
# % pip install -q tensorflow-model-optimizationpi 
import os
import numpy as np
import pandas as pd
import datetime
import tensorflow as tf
from tensorflow import optimizers, losses
from tensorflow.keras import Input
#import tensorflow_addons as tfa
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
#tf.compat.v1.disable_eager_execution()

from jarvis.train import datasets, custom
from jarvis.train.client import Client
from jarvis.utils.general import overload, tools as jtools
from jarvis.utils.db import DB
from model import *

log_dir = "logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
if(not os.path.isdir(log_dir)):
    os.makedirs(log_dir)

datasets.download(name='ct/pna')

@overload(Client)
def preprocess(self, arrays, **kwargs):   
    msk = np.zeros(arrays['xs']['dat'].shape)
    lng = arrays['xs']['lng'] > 0
    pna =  arrays['ys']['pna'] > 0
    msk[lng] = 1
    msk[pna] = 5
    arrays['xs']['lng'] = msk   
    arrays['xs']['dat'] *= 1 * lng
    return arrays

path = '{}\\data\\ymls\\client.yml'.format(jtools.get_paths('ct/pna')['code'])
configs = {'batch':{'fold':0, 'size':4}}
client = Client(path, configs=configs)
gen_train, gen_valid = client.create_generators()
inputs = client.get_inputs(Input)

def sce(weights=None, scale=1.0):
    loss = losses.SparseCategoricalCrossentropy(from_logits=True)
    @tf.function
    def sce(y_true, y_pred):
        return loss(y_true=y_true, y_pred=y_pred, sample_weight=weights) * scale
    return sce

def dsc_soft(weights=None, scale=1.0, epsilon=0.01, cls=1):
    @tf.function
    def dsc(y_true, y_pred):
        true = tf.cast(y_true[..., 0] == cls, tf.float32)
        pred = tf.nn.softmax(y_pred, axis=-1)[..., cls]

        if weights is not None:
            w = tf.cast(weights, tf.float32)     
            true = true * w
            pred = pred * w
        A = tf.math.reduce_sum(true * pred) 
        B = tf.math.reduce_sum(true) + tf.math.reduce_sum(pred) + epsilon
        return  (A * 2.0/ B) * scale
    return dsc

def happy_meal(alpha = 5, beta = 1, weights=None, epsilon=0.01, cls=1):
    l2 = sce(None, alpha)
    l1 = dsc_soft(weights, beta, epsilon, cls)
    @tf.function
    def calc_loss(y_true, y_pred):
        return l2(y_true, y_pred) - l1(y_true, y_pred)
    return calc_loss


def train():    
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./ckp/', save_weights_only=True)

    tensorboard_callback = tf.keras.callbacks.TensorBoard( 
        log_dir,       
        histogram_freq=1,
        write_images=True,
        write_graph=True,
        profile_batch=0, 
    )

    reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='dsc', factor=0.8, patience=2, mode = "max", verbose = 1)
    early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='dsc', patience=20, verbose=0, mode='max', restore_best_weights=False)

    model = dense_unet(inputs, filters=64, fs=2)
    dot_img_file = './model.png'
    tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)
    model.compile(
        optimizer=optimizers.Adam(learning_rate=8e-4),
        loss={'pna': happy_meal(1, 0.5, weights=inputs['lng'])},
        metrics = {'pna': dsc_soft(cls=1, weights=inputs['lng'])},
        experimental_run_tf_function=False
    )

    client.load_data_in_memory()

    model.fit(
        x=gen_train,
        epochs=100,
        steps_per_epoch=400,
        validation_data=gen_valid,
        validation_steps=100,
        validation_freq=5,
        callbacks=[model_checkpoint_callback, reduce_lr_callback, early_stop_callback, tensorboard_callback]        
    )

    _, accuracy = model.evaluate(gen_valid, steps=600)
    return accuracy

def test(model):
    pass
    
if __name__ == "__main__":
    train()

    
    


    
