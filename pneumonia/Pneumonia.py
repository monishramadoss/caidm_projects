# -*- coding: utf-8 -*-
"""cadim pneumonia pna RAUNET

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_rjmMTLespZytwl5bFMe-ao7lI--OzeQ
"""

# Commented out IPython magic to ensure Python compatibility.
# % pip install -q jarvis-md
# % pip install -q tensorflow-model-optimizationpi 

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import optimizers, losses
from tensorflow.keras import Input
#import tensorflow_addons as tfa
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

from jarvis.train import datasets, custom
from jarvis.train.client import Client
from jarvis.utils.general import overload, tools as jtools

from model import RA_UNET

datasets.download(name='ct/pna')
gen_train, gen_valid, client = datasets.prepare(name='ct/pna')

# @overload(Client)
# def preprocess(self, arrays, **kwargs):   
#     lng = arrays['xs']['lng']
#     pna = arrays['ys']['pna']
#     dat = arrays['xs']['dat']
#     #norm = np.linalg.norm(dat)
#     #dat = dat/norm
#     arrays['xs']['lng'] = lng.astype(np.float32)    
#     arrays['xs']['dat'] = dat.astype(np.float32)
#     arrays['ys']['pna'] = pna.astype(np.int64)

#     return arrays

inputs = client.get_inputs(Input)
#scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)

def dice(y_true, y_pred, c=1, epsilon=1):    
    A = 0
    B = 0
    y_true_slice = y_true
    y_pred_slice = y_pred
    true = y_true_slice[..., 0] == c
    pred = np.argmax(y_pred_slice, axis=-1) == c 
    A = np.count_nonzero(true & pred) * 2
    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon    
    return A / B

xs, ys = next(gen_train)
print(np.max(xs['dat']), np.min(xs['dat']))

def dice_coef(y_true, y_pred):
    smoothing = 1e-7
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(tf.keras.backend.argmax(y_pred))
    y_pred_f = tf.cast(y_pred_f, y_true_f.dtype)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smoothing) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smoothing)

def dice_coef_loss(y_true, y_pred):
    dice = 1 - dice_coef(y_true[:,:,:,:,:], y_pred[:,:,:,:,:])    
    #SCCE = scce(y_true, y_pred)
    return dice

def train():
    
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath='./ckp/',
        save_weights_only=True,
        monitor='val_accuracy',
        mode='max',
        save_best_only=True
    )


    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir="./logs", 
        histogram_freq=1,
        write_images=True,
        write_graph=False
    )

    model = RA_UNET(inputs)
    model.compile(
        optimizer=optimizers.Adam(learning_rate=2e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),
        loss={
            'pna': custom.dsc(weights=inputs['lng'])
            },
        metrics={
            'pna': ['accuracy', custom.dsc(weights=inputs['lng'])]
            }        
    )

    model.fit(
        x=gen_train,
        epochs=30,
        steps_per_epoch=2000,
        validation_data=gen_valid,
        validation_steps=500,
        validation_freq=1,
        callbacks=[tensorboard_callback, model_checkpoint_callback]
    )


def test(model):
    lung_seg = []
    for x,y in test_valid:
        logits = model.predict(x)
        if type(logits) is dict:
            logits = logits['pna'] 
        lung_seg.append(dice(y['pna'][0], logits[0]))
    
    lung_seg = np.array(lung_seg)
    print(lung_seg.mean())
    
if __name__ == "__main__":
    train()
    pass
    


    
